---
tags:
- 概率论
include:
- math
---

# Kullback-Leibler散度

KL散度是机器学习中一个非常常用的概念，但是我学概率论的时候老师几乎没有提到。因此关于它的性质我始终一知半解，今天来深度学习一下。

## 熵

KL散度很大程度是从熵这个概念衍生而来的。

熵的定义如下：

!!! definition
    随机变量$X\sim p(x)$，那么其**信息熵**为：
    $$
    H(X) = \mathbb{E}(-\log p(x))
    $$

!!! question "为什么这么定义？"
    信息熵看起来是一个奇怪的泛函。

## KL散度

TBD