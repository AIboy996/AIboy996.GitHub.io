---
tags:
- Alg
- 笔试
- Leetcode
include:
- math
---

# 0420 hikv

## 单选题

考察内容很杂，包括：

1. **概率论**
2. **机器学习**：
    - 样本量趋于无穷，bias如何变化？
    - GMM分布，用何种方法做推断？LSE、EM、MLE、变分推断、梯度下降？
3. **图像处理**：
    - [边缘检测](https://www.cnblogs.com/zhuifeng-mayi/p/9563947.html)算子？Canny算子,Sobel算子,Laplace算子等
    - 二维空间仿射变换，已知三点变换结果的情况下，求第四个点的结果？
    - 卷积感受野计算
4. **深度学习**：
    - （transfer learning）分类问题到检测问题，如何快速迁移？是否只修改最后几层？
    - 梯度消失/爆炸问题，使用sigmoid/tanh能缓解？？
    - `torch.nn`和`torch.autograd`自动梯度
    - LLM中，何种位置编码的外推性最好？
    - 如何高效利用预训练模型？
    - 图检索AP值计算
5. **数据结构**：顺序存储的线性表，进行访问、修改、删除操作的时间复杂度？
6. **操作系统**：堆和栈在编程中的地位？使用L1缓存还是L2缓存？
7. **C语言**：`#include <stdio.h>`和`#include "stdio.h"`有什么区别？

## 多选题

1. 记忆神经元？
    - LSTM/RNN/CNN/ResNet的结构中涉及到记忆吗？
2. 半监督学习、表示学习
    - 流形假设
    - 平滑性假设
    - 聚类假设
    - 分布一致假设
    - 局部性假设
    - 可优化假设
    - 等等
3. Java代码阅读，[两数之和](https://leetcode.cn/problems/two-sum/description/)
4. CNN中数据的预处理？
    - 中性化
    - 归一化
    - PCA
    - label smooth
    - crop
    - rotation
    - 等等

## 问答题

### 单目深度估计

??? chatgpt-summary "单目深度估计中，相对深度和绝对深度有什么区别？"
    在单目深度估计中，「相对深度」和「绝对深度」是两个非常重要但又容易混淆的概念。下面我来帮你理清楚它们的区别：

    ✅ 一句话总结：

    - 绝对深度：真实世界中，从相机到物体的实际物理距离（比如单位是米）。
    - 相对深度：表示图像中物体之间的远近关系或比例，不考虑真实的物理尺度。

    ⸻

    🔍 更具体解释：

    <h3>绝对深度（Absolute Depth）</h3>

    - 是一个有尺度的深度。
    - 反映的是相机到物体的真实距离，比如「这个物体离相机是 2 米，那一个是 5 米」。
    - 需要依赖外部信息（如相机内参、传感器标定）来估计。
    - 更难获取，因为单目图像本身没有尺度信息。

    ✅ 应用场景：

    - 自动驾驶中的导航规划
    - 机器人抓取物体（需要知道真实距离）
    - AR 应用中将虚拟物体放在正确位置

    <h3>相对深度（Relative Depth）</h3>

    - 只关心物体之间哪个更近、哪个更远。
    - 不包含具体的单位或尺度，只保留结构关系。
    - 容易训练，因为人类也很容易标注「这个比那个近」。
    - 输出可能是归一化后的深度图（比如值在 0 到 1 之间）或排序。

    ✅ 应用场景：

    - 图像理解
    - 分割、检测时辅助定位
    - 三维重建的粗略估计

    ⸻

    🧠 举个简单的例子：

    假设你看到一张图，图里有一只猫和一棵树：

    - 相对深度估计模型告诉你：「猫比树更近」。
    - 绝对深度估计模型告诉你：「猫在 1.2 米，树在 5 米」。

原来单目深度估计的意思是，**只用一只眼睛来估计深度**，长见识了。

### 过拟合

??? chatgpt-summary "什么是过拟合？为什么会过拟合？如何处理？"
    过拟合（Overfitting） 是指模型在训练数据上表现很好，但在新数据（测试集）上表现很差的现象。这意味着模型“记住”了训练数据中的细节和噪声，而没有学到真正的规律。

    ⸻

    为什么会过拟合？

    - 模型太复杂（参数太多）
    - 训练数据量太少
    - 数据中有噪声
    - 训练轮数太多

    ⸻

    如何应对过拟合？

    1. 增加数据量（Data Augmentation）
    2. 使用正则化（如 L1/L2 正则）
    3. 简化模型结构
    4. 使用 dropout（神经网络中常用）
    5. 交叉验证（如 K 折交叉验证）
    6. 提前停止训练（Early Stopping）

    需要详细讲解其中某一点吗？

## 手撕代码

Leetcode-[从前序与中序遍历序列构造二叉树](https://leetcode.cn/problems/construct-binary-tree-from-preorder-and-inorder-traversal/description/)
