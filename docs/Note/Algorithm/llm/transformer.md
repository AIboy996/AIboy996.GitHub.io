---
tags:
- Alg
- Papers
- LLM
---

# Transformer

| 组件                | 解决的问题                          | 关键优势                          |
|---------------------|-----------------------------------|----------------------------------|
| 自注意力            | 长距离依赖、并行化                 | 直接建模任意词对关系              |
| 多头注意力          | 单一注意力模式的局限性             | 多视角捕捉特征                    |
| 位置编码            | 自注意力缺乏顺序感知               | 显式注入位置信息                  |
| 残差连接 + LayerNorm| 深层网络训练不稳定                 | 梯度流畅传播                      |
| FFN                 | 注意力层的线性局限                 | 引入非线性变换                    |
| 编码器-解码器       | 序列到序列任务（如翻译）           | 分离上下文编码与生成              |

