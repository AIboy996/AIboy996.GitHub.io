---
tags:
- ML
include:
- math
---

# Bagging & Boosting

é›†æˆå­¦ä¹ ï¼ˆEnsemble learningï¼‰æ–¹æ³•é€šè¿‡ç»„åˆå¤šç§å­¦ä¹ ç®—æ³•æ¥è·å¾—æ¯”å•ç‹¬ä½¿ç”¨ä»»ä½•ä¸€ç§ç®—æ³•æ›´å¥½çš„é¢„æµ‹æ€§èƒ½ã€‚æˆ‘ä»¬åœ¨ä»‹ç»[æ ‘æ¨¡å‹](./tree.md)çš„æ—¶å€™å·²ç»ä»‹ç»äº†ï¼š

- Bagging
- Boosting
- Stacking
- Blending
- Voting

è¿™äº”ç§é›†æˆæ–¹æ³•ï¼Œä¸è¿‡éƒ½æ˜¯åœ¨æ ‘æ¨¡å‹çš„è¯­å¢ƒä¸‹ã€‚å®é™…ä¸Šè¿™äº›æ–¹æ³•ä¸ä»…ä»…å¯ä»¥ç”¨åœ¨æ ‘æ¨¡å‹ä¸Šï¼Œçº¿æ€§æ¨¡å‹ã€SVMç”šè‡³æ˜¯ç¥ç»ç½‘ç»œéƒ½å¯ä»¥ä½¿ç”¨é›†æˆå­¦ä¹ æ–¹æ³•æ¥å¢å¼ºã€‚

GPTå¸®æˆ‘ç”Ÿæˆäº†ä¸€ä¸ªç®€ä»‹ï¼š

|æ–¹æ³•|æ ¸å¿ƒæ€æƒ³|ä»£è¡¨æ¨¡å‹|ä¼˜ç‚¹|é€‚åˆè§£å†³çš„é—®é¢˜|
|--|--|--|--|--|
|Bagging|å¹¶è¡Œè®­ç»ƒå¤šä¸ªæ¨¡å‹+æŠ•ç¥¨/å¹³å‡|éšæœºæ£®æ—|å‡å°‘æ–¹å·®|é«˜æ–¹å·®ã€è¿‡æ‹Ÿåˆé—®é¢˜|
|Boosting|é¡ºåºè®­ç»ƒï¼Œå…³æ³¨å‰ä¸€æ¨¡å‹é”™è¯¯|AdaBoost, XGBoost|å‡å°‘åå·®|é«˜åå·®ã€æ¬ æ‹Ÿåˆé—®é¢˜|
|Stacking|å¤šæ¨¡å‹ç»„åˆ+å…ƒå­¦ä¹ å™¨èåˆè¾“å‡º|è‡ªå®šä¹‰å †å æ¨¡å‹|èåˆå¤šæ¨¡å‹ä¼˜ç‚¹|æé«˜æ³›åŒ–èƒ½åŠ›|
|Voting|å¤šæ¨¡å‹æŠ•ç¥¨æˆ–æ¦‚ç‡å¹³å‡|ç¡¬æŠ•ç¥¨/è½¯æŠ•ç¥¨æ¨¡å‹|ç®€å•å¿«é€Ÿ|æé«˜ç¨³å®šæ€§ã€ç²—ç•¥èåˆé¢„æµ‹|

è¿™é‡Œé¢æœ€å¸¸ç”¨çš„å°±æ˜¯æ¥ä¸‹æ¥è¯¦ç»†ä»‹ç»çš„Baggingå’ŒBoostingã€‚

## Bagging

> Bootstrap Aggregating

æ€æƒ³ï¼šé€šè¿‡å¯¹æ•°æ®é›†è¿›è¡Œæœ‰æ”¾å›çš„æŠ½æ ·ï¼Œç”Ÿæˆå¤šä¸ªè®­ç»ƒå­é›†ï¼Œåˆ†åˆ«è®­ç»ƒå¤šä¸ªåŸºå­¦ä¹ å™¨ï¼ˆé€šå¸¸æ˜¯å¼ºæ–¹å·®ã€ä½åå·®æ¨¡å‹ï¼Œå¦‚å†³ç­–æ ‘ï¼‰ï¼Œæœ€åè¿›è¡ŒæŠ•ç¥¨æˆ–å¹³å‡ã€‚

### Random Forest

[éšæœºæ£®æ—](https://en.wikipedia.org/wiki/Random_forest)æ˜¯æœ€å…·ä»£è¡¨çš„Baggingæ¨¡å‹ï¼Œå…¶ä¸»è¦æ­¥éª¤æ˜¯ï¼š

1. æ•°æ®é‡‡æ ·ï¼ˆBaggingï¼‰ï¼š
    - å¯¹è®­ç»ƒé›†è¿›è¡Œæœ‰æ”¾å›çš„æŠ½æ ·ï¼ˆBootstrapï¼‰ï¼Œç”Ÿæˆå¤šä¸ªä¸åŒçš„å­è®­ç»ƒé›†ï¼›
    - æ¯ä¸ªå­é›†ç”¨äºè®­ç»ƒä¸€æ£µå†³ç­–æ ‘ã€‚
2. ç‰¹å¾é‡‡æ ·ï¼ˆRandom Subspaceï¼‰ï¼š
    - åœ¨æ¯æ£µæ ‘èŠ‚ç‚¹åˆ’åˆ†æ—¶ï¼Œ**éšæœºé€‰å–éƒ¨åˆ†ç‰¹å¾**è¿›è¡Œæœ€ä½³åˆ’åˆ†é€‰æ‹©ï¼ˆè€Œä¸æ˜¯ä½¿ç”¨å…¨éƒ¨ç‰¹å¾ï¼‰
3. é›†æˆé¢„æµ‹ï¼š
    - åˆ†ç±»é—®é¢˜ï¼šå¤šæ•°æŠ•ç¥¨ï¼›
    - å›å½’é—®é¢˜ï¼šå¹³å‡æ‰€æœ‰æ ‘çš„é¢„æµ‹å€¼ã€‚

!!! note
    ğŸ‘‰ å…³é”®ï¼šéšæœºæ€§ + å¤šæ ·æ€§ æé«˜äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼Œå‡å°‘äº†è¿‡æ‹Ÿåˆã€‚


## Boost

æ€æƒ³ï¼šé¡ºåºè®­ç»ƒå¤šä¸ªåŸºå­¦ä¹ å™¨ï¼Œæ¯ä¸€ä¸ªæ–°æ¨¡å‹éƒ½åœ¨å‰ä¸€ä¸ªæ¨¡å‹åŸºç¡€ä¸Šçº æ­£å…¶é”™è¯¯ã€‚é€‚ç”¨äºå‡å°‘åå·®ã€‚

Boostæ–¹æ³•éå¸¸å¤šæ ·ï¼Œæœ€å…·ä»£è¡¨æ€§çš„ä¸¤ç±»å°±æ˜¯ï¼š

- AdaBoost
- Gradient Boosting

### AdaBoost

[Adaptive Boost](https://www.face-rec.org/algorithms/Boosting-Ensemble/decision-theoretic_generalization.pdf)æ˜¯1995å¹´Freundå’ŒSchapiræå‡ºçš„ç®—æ³•ã€‚ä¸‹é¢è¿™å¼ å›¾ï¼ˆæ¥è‡ª[è¿™é‡Œ](https://cseweb.ucsd.edu/~yfreund/papers/IntroToBoosting.pdf)ï¼‰æ¯”è¾ƒæ¸…æ™°åœ°å±•ç¤ºäº†AdaBoostçš„ç®—æ³•æµç¨‹ï¼š

![adaboost](static/adaboost.png)

å…¶ä¸­çš„æ ¸å¿ƒå°±æ˜¯ç»™æ¯ä¸ªæ ·æœ¬èµ‹äºˆ**æƒé‡**ï¼Œåœ¨è¿­ä»£çš„è¿‡ç¨‹ä¸­**é‡ç‚¹å…³æ³¨é‚£äº›è¢«åˆ†ç±»é”™è¯¯çš„æ ·æœ¬**ã€‚

!!! question "æƒé‡æ€ä¹ˆç”¨ï¼Ÿ"
    è¿™é‡Œæœ‰ä¸ªç»†èŠ‚ï¼šå¦‚ä½•ç”¨åŠ æƒçš„æ ·æœ¬è¿›è¡Œè®­ç»ƒï¼Ÿ

    ä¸€èˆ¬æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬åªéœ€è¦æŠŠæƒé‡å¼•å…¥åˆ°æŸå¤±å‡½æ•°ä¸­å³å¯ï¼š
    $$
    \text{Loss} = \sum_{i=1}^m D_t(i) \cdot \text{loss}(h(x_i), y_i)
    $$

    å¦‚æœåœ¨æŸäº›æ¨¡å‹/æ•°æ®ä¸Šåšä¸åˆ°ï¼Œè¿˜å¯ä»¥åˆ©ç”¨è¿­ä»£çš„æƒé‡$D_t$å¯¹æ ·æœ¬åšé‡æŠ½æ ·ã€‚
    

### Gradient Boosting

[Gradient Boosting](https://jerryfriedman.su.domains/ftp/trebst.pdf)æ˜¯1999å¹´Friedmanæå‡ºæ¥çš„ç®—æ³•ã€‚æ ¸å¿ƒæ­¥éª¤å¦‚ä¸‹ï¼š

<figure markdown>
![](static/gradient.png){width=600}
</figure>

æœ¬è´¨ä¸Šæ˜¯åœ¨å‡½æ•°ç©ºé—´ä¸Šçš„æ•°å€¼ä¼˜åŒ–ã€‚æ¯æ¬¡æˆ‘ä»¬å¯»æ‰¾ä¸€ä¸ªä¼˜åŒ–æ–¹å‘$h(x;a_m)$ä»¥åŠæœ€ä½³çš„æ­¥é•¿$\rho_m$.

æ³¨æ„ï¼Œè¿™é‡Œçš„æŸå¤±å‡½æ•°å¯ä»¥å–å¾ˆå¤šç§å½¢å¼ï¼Œä»è€Œå¯¼å‡ºä¸åŒçš„æ¢¯åº¦æå‡æ–¹æ³•ã€‚

??? note "L2 Loss: LS Boost"
    æœ€ç®€å•çš„æƒ…å½¢æ˜¯L2æŸå¤±ï¼ˆLeast squareï¼‰ï¼Œæ­¤æ—¶è´Ÿæ¢¯åº¦ä¸ºï¼š
    $$
    -\frac{\partial L(y, F(x))}{\partial F(x)} = -\frac{\partial (y-F(x))^2}{\partial F(x)} = 2(y-F(x))
    $$

    > æ³¨æ„ï¼Œè¿™æ˜¯ä¸€ä¸ªå‡½æ•°ï¼Œè€Œä¸æ˜¯æ•°å€¼ã€‚å¿½ç•¥æ‰2è¿™ä¸ªç¼©æ”¾ç³»æ•°ï½

    ç„¶åï¼Œæˆ‘ä»¬ç”¨å¦å¤–ä¸€ä¸ªåŸºæ¨¡å‹æ¥æ‹Ÿåˆå®ƒï¼š

    ![alt text](static/ls.png){width=500}

    ä¸éš¾å‘ç°ï¼Œè¿™å®é™…ä¸Šå°±æ˜¯åœ¨ä¸æ–­**æ‹Ÿåˆæ®‹å·®**ï¼

??? note "L1 Loss: LAD Boost"
    å¦‚æœä½¿ç”¨L1æŸå¤±ï¼ˆLeast absolute deviationï¼‰ï¼Œæ­¤æ—¶è´Ÿæ¢¯åº¦ä¸ºï¼š
    $$
    -\frac{\partial L(y, F(x))}{\partial F(x)} = -\frac{\partial |y-F(x)|}{\partial F(x)} = -\mathrm{sign}(y-F(x))
    $$

    ä¾ç„¶ï¼Œæˆ‘ä»¬ç”¨ä¸€ä¸ªåŸºæ¨¡å‹æ¥æ‹Ÿåˆå®ƒã€‚

    è¿™é‡Œæ¯”è¾ƒæœ‰æ„æ€çš„æ˜¯ï¼Œåœ¨L1æŸå¤±ä¸‹ï¼Œæœ€ä½³çš„æ­¥é•¿æœ‰ä¸€ä¸ªæ¼‚äº®çš„å½¢å¼ï¼ˆåŠ æƒä¸­ä½æ•°ï¼‰ï¼š

    <figure markdown>
    ![alt text](static/median.png){width=500}
    </figure>

??? note "Huber Loss: M-Regression"
    ä¸ºäº†å¤„ç†é•¿å°¾æ•°æ®ä»¥åŠå¼‚å¸¸å€¼ï¼Œå¯ä»¥ä½¿ç”¨Huber Lossï¼š
    $$
    L(y,F) = \begin{cases}
    0.5(y-F)^2&|y-F|\le \delta\\\\
    \delta(|y-F|-\delta / 2)&|y-F|\gt \delta\\\\
    \end{cases}
    $$

    æ­¤æ—¶å¯ä»¥å¯¼å‡ºï¼š
    ![alt text](static/huber.png)

### XGBoost

![](https://xgboost.ai/images/logo/xgboost-logo.png){width=300}

XGBoostï¼ˆeXtreme Gradient Boostingï¼‰æ˜¯2016å¹´é™ˆå¤©å¥‡ç­‰äººæå‡ºçš„é’ˆå¯¹æ ‘ç®—æ³•çš„æ¢¯åº¦æå‡æ¡†æ¶ã€‚

ç®—æ³•çš„æœ¬è´¨ä¸Šå’ŒGradient Boostæ²¡å¤šå¤§åŒºåˆ«ï¼ŒGradient Boosting æ˜¯ç®—æ³•æ€æƒ³ï¼Œè€Œ XGBoost æ˜¯è¯¥æ€æƒ³çš„ä¸€ä¸ªé«˜æ•ˆå®ç°ï¼ŒåŠ å…¥äº†æ­£åˆ™ã€äºŒé˜¶å¯¼æ•°ã€å¹¶è¡Œä¼˜åŒ–ç­‰å·¥ç¨‹æ”¹è¿›ã€‚æ›´å¤šç»†èŠ‚å»ºè®®å»çœ‹å®˜æ–¹åº“çš„[æ–‡æ¡£](https://xgboost.readthedocs.io/en/stable/tutorials/model.html#)å’Œ[åŸå§‹è®ºæ–‡](https://arxiv.org/abs/1603.02754)ã€‚

æˆ‘è¿™é‡Œå™è¿°ä¸€ä¸ªç®€æ˜“ç‰ˆæœ¬ï¼š

??? note "XGBoostæ¨å¯¼"
    è®¾æ•°æ®é›†$(x_i, y_i) \in (R^d, R)\quad \forall i\in \\{1,2,\cdots,n\\}$

    å¯¹äºä¸€ä¸ªæ ‘æ¨¡å‹$f(\cdot)$ï¼Œå¯ä»¥åšå¦‚ä¸‹çš„reformulationï¼š

    $$
    f_t(x) = w_{q(x)}
    $$

    å…¶ä¸­$q: R^d\to \\{1,2,3,\cdots, T\\}$ï¼ŒæŠŠè¾“å…¥çš„ç‰¹å¾æ˜ å°„åˆ°æŸä¸€ä¸ªå¶å­ç»“ç‚¹ï¼Œ$w_j$å°±æ˜¯æ¯ä¸ªå¶å­ç»“ç‚¹çš„æœ€ç»ˆé¢„æµ‹ã€‚

    åœ¨è¿™ä¸ªè®°å·ä¸‹å¼•å…¥$l_p$æ­£åˆ™åŒ–ï¼š

    $$
    \Omega_p(f_t) = \gamma T + \frac{1}{2} \lambda \sum_{j=1}^T \mathcal{L}_p (w_j)
    $$

    åœ¨Boostingè¿­ä»£çš„è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬çš„ç›®æ ‡å‡½æ•°æ˜¯ï¼š

    $$
    \mathrm{obj_t}= \sum_{i=1}^n l(y_i, \hat{y_i}^{(t)}) + \Omega_p(f_t)
    $$

    å…¶ä¸­
    $$
    \hat{y_i}^{(t)} = \hat{y_i}^{(t-1)} + f_t(x_i)
    $$
    æ˜¯é€šè¿‡å¤šä¸ªå­¦ä¹ å™¨ç´¯åŠ å¾—åˆ°çš„ã€‚æ¢è¨€ä¹‹$f_t(x_i)$æ¯æ¬¡éƒ½ä¼šæ‹Ÿåˆæ®‹å·®ã€‚

    æˆ‘ä»¬æŠŠæŸå¤±å‡½æ•°åšäºŒé˜¶å±•å¼€ï¼š
    $$
    l(u, v) \approx l(u, v_0) + \frac{\partial l(u, v)}{\partial v}\mid_{v=v_0} (v-v_0) + \frac{1}{2}\frac{\partial^2 l(u, v)}{\partial v^2}\mid_{v=v_0} (v-v_0)^2
    $$
    è®°ï¼š
    $$
    \begin{aligned}
    &g_i = \frac{\partial l(u, v)}{\partial v}\mid_{v=v_0}\\\\
    &h_i = \frac{\partial^2 l(u, v)}{\partial v^2}\mid_{v=v_0}
    \end{aligned}
    $$

    ä»£å…¥$u=y_i, v=\hat{y_i}^{(t)}, v_0=\hat{y_i}^{(t-1)}$ï¼Œå¾—åˆ°ï¼š
    $$
    \begin{aligned}
    &\mathrm{obj_t} \\\\
    \approx& \sum_{i=1}^n \left [l(y_i, \hat{y_i}^{(t-1)}) +g_i (\hat{y_i}^{(t)} - \hat{y_i}^{(t-1)}) +\frac{1}{2} h_i (\hat{y_i}^{(t)} - \hat{y_i}^{(t-1)})^2 \right]  + \Omega_p(f_t)\\\\
    \approx& \sum_{i=1}^n \left [g_i f_t(x_i) +\frac{1}{2}h_i f_t^2(x_i) \right]  + \Omega_p(f_t) + \mathrm{const}\\\\
    \approx& \sum_{i=1}^n \left [g_iw_{q(x_i)}  +\frac{1}{2}h_i w_{q(x_i)}^2 \right]+ \Omega_p(f_t) + \mathrm{const}\\\\
    \approx& \sum_{j=1}^T \left [(\sum_{i: q(x_i) = j} g_i) w_j  + \frac{1}{2}(\sum_{i: q(x_i) = j} h_i) w_j^2 \right] + \gamma T + \frac{1}{2} \lambda \sum_{j=1}^T \mathcal{L}_p (w_j) + \mathrm{const}
    \end{aligned}
    $$

    è®°ï¼š
    $$
    \begin{aligned}
    &G_j = (\sum_{i: q(x_i) = j} g_i) \\\\
    &H_j = (\sum_{i: q(x_i) = j} h_i)
    \end{aligned}
    $$

    ä¸å¦¨å…ˆå–$l_2$æ­£åˆ™åŒ–ï¼Œé‚£ä¹ˆï¼š
    $$
    \mathrm{obj_t} \approx \sum_{j=1}^T \left [ G_j w_j  + \frac{1}{2}H_j w_j^2 \right] + \gamma T + \frac{1}{2} \lambda \sum_{j=1}^T w_j^2 + \mathrm{const}
    $$
    ä¹Ÿå°±æ˜¯ï¼š
    $$
    \mathrm{obj_t} \approx \sum_{j=1}^T \left [ G_j w_j  + \frac{1}{2}(H_j + \lambda) w_j^2 \right] + \gamma T + \mathrm{const}
    $$

    è¿™ä¸ªå¼å­å…³äºæ¯ä¸ªå¶å­èŠ‚ç‚¹$w_j$éƒ½æ˜¯äºŒæ¬¡å‡½æ•°ï¼Œç«‹å³å¾—åˆ°æœ€ä¼˜è§£ï¼š
    $$
    w_j^\dagger = -\frac{G_j}{H_j+\lambda}
    $$
    æ­¤æ—¶ç›®æ ‡å‡½æ•°å€¼ä¸ºï¼š
    $$
    \mathrm{obj_t}^\dagger = -\frac{1}{2} \sum_{j=1}^T\frac{G_j^2}{H_j+\lambda} + \gamma T
    $$

    è¿™å°±æ˜¯ä¸€æ£µæ ‘æœ€ä¼˜çš„æŸå¤±ï¼š

    <figure markdown>
    ![](https://raw.githubusercontent.com/dmlc/web-data/master/xgboost/model/struct_score.png){width=500}
    <figure>

    åœ¨**å•æ£µæ ‘ç”Ÿé•¿**çš„è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥ä½¿ç”¨æ¨å¯¼å‡ºçš„æœ€ä¼˜æŸå¤±æ¥è®¡ç®—å¢ç›Šï¼Œä»è€Œé€‰æ‹©æœ€ä¼˜çš„åˆ†è£‚èŠ‚ç‚¹ï¼š
    $$
    \mathrm{gain} = \frac{1}{2} \left[\frac{G_L^2}{H_L+\lambda}+\frac{G_R^2}{H_R+\lambda}-\frac{(G_L+G_R)^2}{H_{L}+H_R+\lambda}  \right] - \gamma T
    $$
    æˆ–è€…ç­‰ä»·çš„ï¼š
    $$
    \mathrm{gain} = \frac{G_L^2}{H_L+\lambda}+\frac{G_R^2}{H_R+\lambda}-\frac{(G_L+G_R)^2}{H_{L}+H_R+\lambda}
    $$

### LightGBM

![](https://lightgbm.readthedocs.io/en/stable/_images/LightGBM_logo_black_text.svg){width=300}

[LightGBM](https://lightgbm.readthedocs.io/en/stable/)æ˜¯å¾®è½¯å‘å¸ƒçš„Gradient Boostingæ¡†æ¶ï¼Œä¸»è¦åŸºäºå‘è¡¨åœ¨NIPS 2017ä¸Šçš„ä¸€ç¯‡[æ–‡ç« ](https://papers.nips.cc/paper_files/paper/2017/hash/6449f44a102fde848669bdd9eb6b76fa-Abstract.html)ã€‚å¬åå­—ä¹Ÿèƒ½æ„Ÿå—åˆ°ï¼ŒLGBMä¸»æ‰“ä¸€ä¸ª**è½»é‡åŒ–**ï¼Œé€Ÿåº¦éå¸¸å¿«ï¼

LGBMå’ŒXGBoostçš„å¼‚åŒå¯ä»¥çœ‹ä¸€ä¸‹[è¿™ç¯‡æ–‡ç« ](https://neptune.ai/blog/xgboost-vs-lightgbm)ä»¥åŠå®˜æ–¹æä¾›çš„[Featuresè§£è¯»](https://github.com/microsoft/LightGBM/blob/master/docs/Features.rst)ã€‚

LGBMçš„ä¸»è¦è´¡çŒ®å°±æ˜¯ä¸‹é¢å››ä¸ªç®—æ³•ï¼š

??? note "LGBMç»†èŠ‚"
    1. åŸºäºç›´æ–¹å›¾çš„èŠ‚ç‚¹åˆ†è£‚ï¼šåŠ é€Ÿã€èŠ‚çœå†…å­˜ï¼Œä½†æ˜¯ç‰ºç‰²ä¸€å®šçš„ç²¾åº¦
        - æ³¨æ„è¿™é‡Œç”Ÿé•¿çš„æ—¶å€™æ˜¯leaf-wiseçš„ï¼Œä¸€æ¬¡åªé•¿ä¸€ä¸ªå¶å­ç»“ç‚¹ï¼Œè¿™æ ·å¯ä»¥æé«˜ç²¾åº¦ï¼Œä½†æ˜¯ç‰ºç‰²ä¸€å®šçš„æ³›åŒ–æ€§
        - è€ŒXGBoostæ˜¯level-wiseçš„ï¼Œä¸€æ¬¡é•¿ä¸€å±‚
    2. GOSSï¼šåŸºäºæ¢¯åº¦çš„é™é‡‡æ ·
        - ä¿ç•™æ¢¯åº¦ï¼ˆåœ¨L2æŸå¤±ä¸‹å°±æ˜¯æ®‹å·®ï¼‰è¾ƒå¤§çš„æ ·æœ¬ï¼Œå’ŒAdaBoostæƒ³æ³•ç±»ä¼¼
        - é™é‡‡æ ·æ¢¯åº¦è¾ƒå°çš„æ ·æœ¬ï¼Œå®ƒä»¬å·²ç»å­¦çš„æ¯”è¾ƒå¥½äº†
        - å¦‚æ­¤å¯ä»¥æå¤§å‡å°‘æ ·æœ¬é‡ï¼Œæé«˜è®­ç»ƒé€Ÿåº¦
        ![alt text](static/lgbm.png)
    3. Greedy Bundlingï¼šè´ªå¿ƒç®—æ³•æ±‚è§£å˜é‡æ†ç»‘é—®é¢˜
        - å¯»æ‰¾å¯ä»¥æ†ç»‘åœ¨ä¸€èµ·çš„å˜é‡
        - ä¾‹å¦‚`x=[1,0,0,0]`, `y=[0,0,1,1]`ï¼Œå¯ä»¥å‘ç°è¿™ä¸¤ä¸ªå˜é‡**ä¸ä¼šåœ¨åŒä¸€ä¸ªä½ç½®å–åˆ°éé›¶**
        - é‚£ä¹ˆå®ƒä»¬å®Œå…¨å¯ä»¥åˆå¹¶ä¸º`z=[1,0,2,2]`
    4. Merge Exclusive Featuresï¼šåˆå¹¶æ‰“åŒ…çš„å˜é‡
        - å¯¹äºæ‰¾åˆ°çš„å¯ä»¥æ†ç»‘çš„å˜é‡ï¼ŒæŠŠå®ƒä»¬mergeä¸ºä¸€ä¸ªå˜é‡
        - MEFè¿™å—å¯ä»¥çœ‹ä¸€çœ‹è¿™ä½å¤§ä½¬çš„[çŸ¥ä¹ä¸“æ ](https://zhuanlan.zhihu.com/p/366234433?ivk_sa=1024320u)
        - è¿™ä¸¤ä¸ªç®—æ³•ä¸»è¦æ˜¯ä¸ºäº†è§£å†³**é«˜ç»´æ•°æ®ç¨€ç–**çš„é—®é¢˜ï¼Œé€šè¿‡å˜é‡çš„åˆå¹¶é™ä½ç»´åº¦å®ç°åŠ é€Ÿ
        ![alt text](static/mef.png)

æ­¤å¤–ï¼ŒLGBMè¿˜å¯¹ç±»åˆ«å˜é‡åšäº†[ç‰¹åˆ«æ”¯æŒ](https://github.com/microsoft/LightGBM/blob/master/docs/Features.rst#optimal-split-for-categorical-features)ï¼Œç›´æ¥çœ‹GPTçš„å›ç­”å§ï¼š

??? chatgpt-summary "LGBMå¯¹ç±»åˆ«å˜é‡æœ‰ä»€ä¹ˆä¼˜åŒ–ï¼Ÿ"
    LightGBM å¯¹ç±»åˆ«å˜é‡ï¼ˆcategorical featuresï¼‰åšäº†éå¸¸é«˜æ•ˆçš„åŸç”Ÿä¼˜åŒ–ï¼Œè¿™ä¹Ÿæ˜¯å®ƒç›¸æ¯”å…¶ä»–æ¡†æ¶ï¼ˆå¦‚ XGBoostï¼‰çš„ä¸€å¤§ä¼˜åŠ¿ã€‚ä½ ä¸éœ€è¦è¿›è¡Œç‹¬çƒ­ç¼–ç ï¼ˆone-hotï¼‰æˆ–æ ‡ç­¾ç¼–ç ï¼ˆlabel encodingï¼‰ï¼Œå®ƒå¯ä»¥ç›´æ¥å¤„ç†ç±»åˆ«ç‰¹å¾ï¼Œå¹¶ä¸”å¤„ç†å¾—æ›´å¿«ã€æ›´å‡†ã€‚

    #### 1. åŸç”Ÿæ”¯æŒç±»åˆ«ç‰¹å¾

    LightGBM å¯ä»¥ç›´æ¥æ¥æ”¶ç±»åˆ«ç‰¹å¾çš„åˆ—ï¼Œæ— éœ€æ‰‹åŠ¨ç¼–ç ï¼Œåªéœ€å‘Šè¯‰å®ƒå“ªäº›åˆ—æ˜¯ç±»åˆ«å˜é‡ï¼ˆæ¯”å¦‚ç”¨ categorical_feature å‚æ•°ï¼‰ã€‚

    #### 2. ç›´æ–¹å›¾åˆ†æ¡¶

    LightGBM ä¸æŒ‰æ•°å€¼é¡ºåºå»åˆ†è£‚ç±»åˆ«å˜é‡ï¼ˆå› ä¸ºç±»åˆ«æ²¡æœ‰è‡ªç„¶çš„å¤§å°å…³ç³»ï¼‰ï¼Œè€Œæ˜¯ä½¿ç”¨ä»¥ä¸‹ç­–ç•¥æ¥åšåˆ†è£‚ï¼š

    > åŸç†ï¼šç±»åˆ«æ’åº + äºŒå…ƒåˆ†è£‚

    1.	æŒ‰ç±»åˆ«èšåˆæ¢¯åº¦ç»Ÿè®¡
        - è®¡ç®—æ¯ä¸ªç±»åˆ«ä¸Šçš„æ ·æœ¬çš„ æ¢¯åº¦ä¹‹å’Œï¼ˆgï¼‰å’Œ Hessian ä¹‹å’Œï¼ˆhï¼‰
    2.	å¯¹ç±»åˆ«æŒ‰æŸç§æŒ‡æ ‡æ’åº
        - é€šå¸¸æ˜¯æŒ‰ g / h æˆ– g å€¼æ’åºï¼Œä»£è¡¨æ¯ä¸ªç±»åˆ«å¯¹ç›®æ ‡çš„å½±å“åŠ›
    3.	å°†ç±»åˆ«é›†åˆäºŒåˆ†
        - è¯•å‡ºä¸åŒçš„åˆ‡åˆ†ç‚¹ï¼ˆç±»ä¼¼äºæ•°å€¼å‹çš„åˆ†è£‚ç‚¹ï¼‰ï¼Œä»è€Œæ‰¾åˆ°æœ€å¤§å¢ç›Šçš„åˆ†è£‚æ–¹å¼ã€‚

    è¿™ç§æ–¹å¼å«åš Greedy Groupingï¼ˆè´ªå©ªåˆ†ç»„ï¼‰ï¼Œå¯ä»¥æœ‰æ•ˆæ‰¾åˆ°å¯¹ç›®æ ‡æœ€æœ‰å½±å“çš„ç±»åˆ«ç»„åˆã€‚

    #### 3. æ¯” one-hot ç¼–ç æ›´å¿«æ›´å‡†

    |æ–¹æ³•|ç¼ºç‚¹|LightGBM çš„ä¼˜åŠ¿|
    |--|--|--|
    |One-hot|ç»´åº¦çˆ†ç‚¸ï¼Œç¨€ç–çŸ©é˜µï¼Œè®­ç»ƒæ…¢|ä¸å¢åŠ ç»´åº¦ï¼Œé€Ÿåº¦å¿«|
    |Label encoding|ç¼–ç æœ‰éšå«é¡ºåºï¼Œå¼•å…¥ä¼ªå…³ç³»|ä¸ä¾èµ–ç¼–ç é¡ºåºï¼ŒåŸºäºç»Ÿè®¡åˆ†è£‚|

    #### ä¸¾ä¸ªä¾‹å­

    å‡è®¾ä¸€ä¸ªâ€œé¢œè‰²â€ç‰¹å¾æœ‰ 4 ä¸ªç±»åˆ«ï¼š[Red, Blue, Green, Yellow]

    1.	LightGBM ä¼šç»Ÿè®¡è¿™å››ä¸ªé¢œè‰²çš„æ¢¯åº¦ä¿¡æ¯ï¼ˆæ®‹å·®ï¼‰
        - æ¯”å¦‚ï¼šRed=0.5, Blue=1.2, Green=0.1, Yellow=-0.6
    2.	ç„¶åæŒ‰ç…§è¿™äº›å€¼è¿›è¡Œæ’åºï¼Œæ¯”å¦‚ï¼š[Yellow, Green, Red, Blue]
    3.	å°è¯•å°†è¿™äº›ç±»åˆ«åˆ‡åˆ†æˆä¸¤ç»„ï¼Œæ¯”å¦‚ï¼š[Yellow, Green] vs [Red, Blue]
    4.	åˆ†è£‚ç‚¹é€‰å–ä¾æ®æ˜¯å“ªä¸ªåˆ’åˆ†å¸¦æ¥æœ€å¤§å¢ç›Šï¼ˆinformation gainï¼‰
